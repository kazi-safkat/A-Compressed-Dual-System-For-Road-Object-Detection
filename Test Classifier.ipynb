{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cc50f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 172 ms (started: 2024-05-05 23:35:08 +06:00)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from pycocotools.coco import COCO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, cohen_kappa_score, classification_report, confusion_matrix\n",
    "from scipy.stats import rankdata\n",
    "from numpy import linalg as LA\n",
    "# import intel_extension_for_pytorch as ipex\n",
    "\n",
    "%load_ext autotime\n",
    "\n",
    "# import albumentations as A\n",
    "# from albumentations.pytorch import ToTensorV2\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "import time\n",
    "import os\n",
    "plt.style.use('ggplot')\n",
    "device = 'cuda'\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.lr_scheduler import StepLR, MultiStepLR\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d3cc77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2024-05-05 23:35:13 +06:00)\n"
     ]
    }
   ],
   "source": [
    "class_dictionary = {1: 'person', 2: 'bike', 3: 'car', 4: 'motor', 6: 'bus',  7: 'train', 8: 'truck', 10: 'light', \n",
    "                   11: 'hydrant', 12: 'sign', 17: 'dog', 37: 'skateboard', 73: 'stroller', 77: 'scooter', 79: 'other vehicle'\n",
    "                   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc30980c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16 ms (started: 2024-05-05 23:35:13 +06:00)\n"
     ]
    }
   ],
   "source": [
    "##################################################################\n",
    "#   Utils\n",
    "##################################################################\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Tensorboard logger code referenced from:\n",
    "https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/04-utils/\n",
    "Other helper functions:\n",
    "https://github.com/cs230-stanford/cs230-stanford.github.io\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "from collections import OrderedDict\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "# import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.misc \n",
    "try:\n",
    "    from StringIO import StringIO  # Python 2.7\n",
    "except ImportError:\n",
    "    from io import BytesIO         # Python 3.x\n",
    "\n",
    "\n",
    "class Params():\n",
    "    \"\"\"Class that loads hyperparameters from a json file.\n",
    "\n",
    "    Example:\n",
    "    ```\n",
    "    params = Params(json_path)\n",
    "    print(params.learning_rate)\n",
    "    params.learning_rate = 0.5  # change the value of learning_rate in params\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, json_path):\n",
    "        with open(json_path) as f:\n",
    "            params = json.load(f)\n",
    "            self.__dict__.update(params)\n",
    "\n",
    "    def save(self, json_path):\n",
    "        with open(json_path, 'w') as f:\n",
    "            json.dump(self.__dict__, f, indent=4)\n",
    "            \n",
    "    def update(self, json_path):\n",
    "        \"\"\"Loads parameters from json file\"\"\"\n",
    "        with open(json_path) as f:\n",
    "            params = json.load(f)\n",
    "            self.__dict__.update(params)\n",
    "\n",
    "    @property\n",
    "    def dict(self):\n",
    "        \"\"\"Gives dict-like access to Params instance by `params.dict['learning_rate']\"\"\"\n",
    "        return self.__dict__\n",
    "\n",
    "\n",
    "class RunningAverage():\n",
    "    \"\"\"A simple class that maintains the running average of a quantity\n",
    "    \n",
    "    Example:\n",
    "    ```\n",
    "    loss_avg = RunningAverage()\n",
    "    loss_avg.update(2)\n",
    "    loss_avg.update(4)\n",
    "    loss_avg() = 3\n",
    "    ```\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.steps = 0\n",
    "        self.total = 0\n",
    "    \n",
    "    def update(self, val):\n",
    "        self.total += val\n",
    "        self.steps += 1\n",
    "    \n",
    "    def __call__(self):\n",
    "        return self.total/float(self.steps)\n",
    "\n",
    "class AverageMeter(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val*n\n",
    "        self.count += n\n",
    "        self.avg = self.sum/self.count\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "def set_logger(log_path):\n",
    "    \"\"\"Set the logger to log info in terminal and file `log_path`.\n",
    "\n",
    "    In general, it is useful to have a logger so that every output to the terminal is saved\n",
    "    in a permanent file. Here we save it to `model_dir/train.log`.\n",
    "\n",
    "    Example:\n",
    "    ```\n",
    "    logging.info(\"Starting training...\")\n",
    "    ```\n",
    "\n",
    "    Args:\n",
    "        log_path: (string) where to log\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "    if not logger.handlers:\n",
    "        # Logging to a file\n",
    "        file_handler = logging.FileHandler(log_path)\n",
    "        file_handler.setFormatter(logging.Formatter('%(asctime)s:%(levelname)s: %(message)s'))\n",
    "        logger.addHandler(file_handler)\n",
    "\n",
    "        # Logging to console\n",
    "        stream_handler = logging.StreamHandler()\n",
    "        stream_handler.setFormatter(logging.Formatter('%(message)s'))\n",
    "        logger.addHandler(stream_handler)\n",
    "\n",
    "\n",
    "def save_dict_to_json(d, json_path):\n",
    "    \"\"\"Saves dict of floats in json file\n",
    "\n",
    "    Args:\n",
    "        d: (dict) of float-castable values (np.float, int, float, etc.)\n",
    "        json_path: (string) path to json file\n",
    "    \"\"\"\n",
    "    with open(json_path, 'w') as f:\n",
    "        # We need to convert the values to float for json (it doesn't accept np.array, np.float, )\n",
    "        d = {k: float(v) for k, v in d.items()}\n",
    "        json.dump(d, f, indent=4)\n",
    "\n",
    "\n",
    "def save_checkpoint(state, is_best, checkpoint, epoch_checkpoint = False):\n",
    "    \"\"\"Saves model and training parameters at checkpoint + 'last.pth.tar'. If is_best==True, also saves\n",
    "    checkpoint + 'best.pth.tar'\n",
    "\n",
    "    Args:\n",
    "        state: (dict) contains model's state_dict, may contain other keys such as epoch, optimizer state_dict\n",
    "        is_best: (bool) True if it is the best model seen till now\n",
    "        checkpoint: (string) folder where parameters are to be saved\n",
    "    \"\"\"\n",
    "    filepath = os.path.join(checkpoint, 'last.pth.tar')\n",
    "    if not os.path.exists(checkpoint):\n",
    "        print(\"Checkpoint Directory does not exist! Making directory {}\".format(checkpoint))\n",
    "        os.mkdir(checkpoint)\n",
    "    else:\n",
    "        print(\"Checkpoint Directory exists! \")\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(checkpoint, 'best.pth.tar'))\n",
    "    if epoch_checkpoint == True:\n",
    "        epoch_file = str(state['epoch']-1) + '.pth.tar'\n",
    "        shutil.copyfile(filepath, os.path.join(checkpoint, epoch_file))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint, model, optimizer=None):\n",
    "    \"\"\"Loads model parameters (state_dict) from file_path. If optimizer is provided, loads state_dict of\n",
    "    optimizer assuming it is present in checkpoint.\n",
    "\n",
    "    Args:\n",
    "        checkpoint: (string) filename which needs to be loaded\n",
    "        model: (torch.nn.Module) model for which the parameters are loaded\n",
    "        optimizer: (torch.optim) optional: resume optimizer from checkpoint\n",
    "    \"\"\"\n",
    "    try:\n",
    "\n",
    "      if not os.path.exists(checkpoint):\n",
    "        raise FileNotFoundError\n",
    "    except FileNotFoundError:\n",
    "      (\"File doesn't exist {}\".format(checkpoint))\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        checkpoint = torch.load(checkpoint)\n",
    "    else:\n",
    "        # this helps avoid errors when loading single-GPU-trained weights onto CPU-model\n",
    "        checkpoint = torch.load(checkpoint, map_location=lambda storage, loc: storage)\n",
    "\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "    if optimizer:\n",
    "        optimizer.load_state_dict(checkpoint['optim_dict'])\n",
    "\n",
    "    return checkpoint\n",
    "\n",
    "\n",
    "class WarmUpLR(_LRScheduler):\n",
    "    \"\"\"warmup_training learning rate scheduler\n",
    "    Args:\n",
    "        optimizer: optimzier(e.g. SGD)\n",
    "        total_iters: totoal_iters of warmup phase\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, optimizer, total_iters, last_epoch=-1):\n",
    "        self.total_iters = total_iters\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        \"\"\"we will use the first m batches, and set the learning\n",
    "        rate to base_lr * m / total_iters\n",
    "        \"\"\"\n",
    "        return [base_lr * self.last_epoch / (self.total_iters + 1e-8) for base_lr in self.base_lrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21eb1fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2024-05-05 23:35:14 +06:00)\n"
     ]
    }
   ],
   "source": [
    "transform = {\n",
    "        'train': torchvision.transforms.Compose([\n",
    "            torchvision.transforms.Resize([64,64]), # Resizing the image as the VGG only take 224 x 244 as input size\n",
    "            torchvision.transforms.RandomHorizontalFlip(), # Flip the data horizontally\n",
    "            #TODO if it is needed, add the random crop\n",
    "            torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "#             transforms.Normalize(mean=(0.5,0.5,0.5), std=(0.5,0.5,0.5))\n",
    "        ]),\n",
    "        'test': torchvision.transforms.Compose([\n",
    "            torchvision.transforms.Resize([64,64]),\n",
    "#             transforms.RandomHorizontalFlip(),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "#             transforms.Normalize(mean=(0.5,0.5,0.5), std=(0.5,0.5,0.5))\n",
    "        ])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ef6bd8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.08 s (started: 2024-05-05 23:35:16 +06:00)\n"
     ]
    }
   ],
   "source": [
    "train_data_dir = '.\\\\train_images'\n",
    "# train_coco = 'images_thermal_train/coco.json'\n",
    "val_train_dir = '.\\\\val_images'\n",
    "# val_coco = 'images_thermal_val/coco.json'\n",
    "batch_size = 128\n",
    "\n",
    "train_data = torchvision.datasets.ImageFolder(root=train_data_dir, transform=transform['train'])\n",
    "train_dataloader_class = torch.utils.data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_data = torchvision.datasets.ImageFolder(root=val_train_dir, transform=transform['test'])\n",
    "val_dataloader_class = torch.utils.data.DataLoader(dataset=val_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ed912ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 47 ms (started: 2024-05-05 23:35:17 +06:00)\n"
     ]
    }
   ],
   "source": [
    "from openvino.runtime.ie_api import CompiledModel\n",
    "from typing import Union\n",
    "\n",
    "\n",
    "def validate(model, val_loader):\n",
    "    \"\"\"Compute the metrics using data from val_loader for the model\"\"\"\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    data_sc = []\n",
    "    data_rc = []\n",
    "    start_time = time.time()\n",
    "    # Switch to evaluate mode.\n",
    "    if not isinstance(model, CompiledModel):\n",
    "        model.eval()\n",
    "        model.to(torch_device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, labels_batch) in enumerate(val_loader):\n",
    "            images = images.to('cpu')\n",
    "            labels_batch = labels_batch.to('cpu')\n",
    "\n",
    "            # Compute the output.\n",
    "            if isinstance(model, CompiledModel):\n",
    "                output_layer = model.output(0)\n",
    "                output = model(images)[output_layer]\n",
    "                output_batch = torch.from_numpy(output)\n",
    "#             print(output)\n",
    "            loss = 0.0  # force validation loss to zero to reduce computation time\n",
    "            _, predicted = output_batch.max(1)\n",
    "            total += labels_batch.size(0)\n",
    "            correct += predicted.eq(labels_batch).sum().item()\n",
    "            predicted = predicted.cpu().data.numpy()\n",
    "            labels_batch = labels_batch.cpu().data.numpy()\n",
    "            data_sc.extend(predicted)\n",
    "            data_rc.extend(labels_batch)\n",
    "\n",
    "    #         break\n",
    "    #     print(data_rc)\n",
    "        fscore = f1_score(data_rc, data_sc, average = 'weighted')\n",
    "        precision = precision_score(data_rc, data_sc, average = 'weighted')\n",
    "        recall = recall_score(data_rc, data_sc, average = 'weighted')\n",
    "        kappa = cohen_kappa_score(data_rc, data_sc)\n",
    "        C = classification_report(data_rc, data_sc)\n",
    "        matrix = confusion_matrix(data_rc, data_sc)\n",
    "        accuracy_class = matrix.diagonal()/matrix.sum(axis=1)\n",
    "\n",
    "        print(\"Precision: \", precision)\n",
    "        print(\"Recall: \", recall)\n",
    "        print(\"Report: \", C)\n",
    "        print(\"F1: \", fscore)\n",
    "        print(\"Kappa: \", kappa)\n",
    "        print(\"Matrix: \", matrix)\n",
    "        print(\"Accuracy Class: \", accuracy_class)\n",
    "\n",
    "        acc = 100. * correct / total\n",
    "        logging.info(\"- Eval metrics, acc:{acc:.4f}, loss: {loss:.4f}\".format(acc=acc, loss=loss))\n",
    "        my_metric = {'accuracy': acc, 'loss': loss}\n",
    "        #my_metric['accuracy'] = acc\n",
    "        return my_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76a89865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2024-05-02 06:18:54 +06:00)\n"
     ]
    }
   ],
   "source": [
    "def get_model_size(ir_path, m_type: str = \"Mb\", verbose: bool = True) -> float:\n",
    "    xml_size = os.path.getsize(ir_path)\n",
    "    bin_size = os.path.getsize(os.path.splitext(ir_path)[0] + \".bin\")\n",
    "    for t in [\"bytes\", \"Kb\", \"Mb\"]:\n",
    "        if m_type == t:\n",
    "            break\n",
    "        xml_size /= 1024\n",
    "        bin_size /= 1024\n",
    "    model_size = xml_size + bin_size\n",
    "    if verbose:\n",
    "        print(f\"Model graph (xml):   {xml_size:.3f} {m_type}\")\n",
    "        print(f\"Model weights (bin): {bin_size:.3f} {m_type}\")\n",
    "        print(f\"Model size:          {model_size:.3f} {m_type}\")\n",
    "    return model_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3d8ff81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/7] Save INT8 model: .\\classifier\\quantized_model.xml\n",
      "Model graph (xml):   0.162 Mb\n",
      "Model weights (bin): 10.692 Mb\n",
      "Model size:          10.854 Mb\n",
      "time: 0 ns (started: 2024-05-02 06:18:55 +06:00)\n"
     ]
    }
   ],
   "source": [
    "int8_ir_path = \".\\\\classifier\\\\quantized_model.xml\"\n",
    "print(f\"[2/7] Save INT8 model: {int8_ir_path}\")\n",
    "int8_model_size = get_model_size(int8_ir_path, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f5e3612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.89324738337159\n",
      "Recall:  0.895336159903089\n",
      "Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.87      0.91      4465\n",
      "           1       0.87      0.83      0.85      1945\n",
      "           2       0.40      0.34      0.37        93\n",
      "           3       0.79      0.89      0.83      2384\n",
      "           4       0.67      0.76      0.71       170\n",
      "           5       0.93      0.98      0.95      7101\n",
      "           6       0.00      0.00      0.00         3\n",
      "           7       0.62      0.29      0.40        55\n",
      "           8       0.58      0.35      0.43       179\n",
      "           9       0.00      0.00      0.00         6\n",
      "          10       0.37      0.17      0.24        63\n",
      "          11       0.33      0.02      0.04        46\n",
      "\n",
      "    accuracy                           0.90     16510\n",
      "   macro avg       0.54      0.46      0.48     16510\n",
      "weighted avg       0.89      0.90      0.89     16510\n",
      "\n",
      "F1:  0.8918310025007341\n",
      "Kappa:  0.850858600164687\n",
      "Matrix:  [[3879   91   47  241   30  175    0    0    1    0    1    0]\n",
      " [  36 1610    2  263    0   33    0    0    1    0    0    0]\n",
      " [  33    4   32    6    4   14    0    0    0    0    0    0]\n",
      " [  16  128    0 2111    3  121    0    0    1    0    3    1]\n",
      " [  13    0    0    1  129   17    0    6    0    0    4    0]\n",
      " [  46   23    0   56   14 6931    0    4   19    0    7    1]\n",
      " [   0    0    0    0    0    3    0    0    0    0    0    0]\n",
      " [   7    0    0    1    6   23    0   16    0    0    2    0]\n",
      " [   3    0    0    2    0  111    0    0   62    0    1    0]\n",
      " [   0    0    0    0    0    6    0    0    0    0    0    0]\n",
      " [   4    0    0    5    6   33    0    0    4    0   11    0]\n",
      " [   1    0    0    2    0   22    0    0   19    0    1    1]]\n",
      "Accuracy Class:  [0.868757   0.8277635  0.34408602 0.88548658 0.75882353 0.97605971\n",
      " 0.         0.29090909 0.34636872 0.         0.17460317 0.02173913]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Downloads\\FLIR_ADAS_v2\\FLIRA\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\Downloads\\FLIR_ADAS_v2\\FLIRA\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\Downloads\\FLIR_ADAS_v2\\FLIRA\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\Downloads\\FLIR_ADAS_v2\\FLIRA\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 89.5336159903089, 'loss': 0.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 46.5 s (started: 2024-05-02 07:24:11 +06:00)\n"
     ]
    }
   ],
   "source": [
    "import openvino as ov\n",
    "\n",
    "core = ov.Core()\n",
    "model = core.read_model(model=int8_ir_path)\n",
    "compiled_model = core.compile_model(model=model, device_name='CPU')\n",
    "validate(compiled_model, val_dataloader_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a904754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.89324738337159\n",
      "Recall:  0.895336159903089\n",
      "Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.87      0.91      4465\n",
      "           1       0.87      0.83      0.85      1945\n",
      "           2       0.40      0.34      0.37        93\n",
      "           3       0.79      0.89      0.83      2384\n",
      "           4       0.67      0.76      0.71       170\n",
      "           5       0.93      0.98      0.95      7101\n",
      "           6       0.00      0.00      0.00         3\n",
      "           7       0.62      0.29      0.40        55\n",
      "           8       0.58      0.35      0.43       179\n",
      "           9       0.00      0.00      0.00         6\n",
      "          10       0.37      0.17      0.24        63\n",
      "          11       0.33      0.02      0.04        46\n",
      "\n",
      "    accuracy                           0.90     16510\n",
      "   macro avg       0.54      0.46      0.48     16510\n",
      "weighted avg       0.89      0.90      0.89     16510\n",
      "\n",
      "F1:  0.8918310025007341\n",
      "Kappa:  0.850858600164687\n",
      "Matrix:  [[3879   91   47  241   30  175    0    0    1    0    1    0]\n",
      " [  36 1610    2  263    0   33    0    0    1    0    0    0]\n",
      " [  33    4   32    6    4   14    0    0    0    0    0    0]\n",
      " [  16  128    0 2111    3  121    0    0    1    0    3    1]\n",
      " [  13    0    0    1  129   17    0    6    0    0    4    0]\n",
      " [  46   23    0   56   14 6931    0    4   19    0    7    1]\n",
      " [   0    0    0    0    0    3    0    0    0    0    0    0]\n",
      " [   7    0    0    1    6   23    0   16    0    0    2    0]\n",
      " [   3    0    0    2    0  111    0    0   62    0    1    0]\n",
      " [   0    0    0    0    0    6    0    0    0    0    0    0]\n",
      " [   4    0    0    5    6   33    0    0    4    0   11    0]\n",
      " [   1    0    0    2    0   22    0    0   19    0    1    1]]\n",
      "Accuracy Class:  [0.868757   0.8277635  0.34408602 0.88548658 0.75882353 0.97605971\n",
      " 0.         0.29090909 0.34636872 0.         0.17460317 0.02173913]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Downloads\\FLIR_ADAS_v2\\FLIRA\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\Downloads\\FLIR_ADAS_v2\\FLIRA\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\Downloads\\FLIR_ADAS_v2\\FLIRA\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\Downloads\\FLIR_ADAS_v2\\FLIRA\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 89.5336159903089, 'loss': 0.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.81 s (started: 2024-05-02 07:25:11 +06:00)\n"
     ]
    }
   ],
   "source": [
    "validate(compiled_model, val_dataloader_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9283ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
